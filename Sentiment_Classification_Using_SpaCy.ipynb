{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Classification Using SpaCy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmXZmY5l54lQwYNMdDeWqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krutarth45/Sentiment-Classification-using-SpaCy/blob/master/Sentiment_Classification_Using_SpaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDnsGjKidRQp",
        "colab_type": "text"
      },
      "source": [
        "### Importing Necessary Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPuiBRl7aHiC",
        "colab_type": "code",
        "outputId": "8883b945-f874-4700-e8c8-d5d6fffba8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "import string\n",
        "# Importing Dataset from the Github Repository.\n",
        "!git clone https://github.com/laxmimerit/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujppuMjbTOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Spacy small model as nlp\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m90EIAg5cTQG",
        "colab_type": "code",
        "outputId": "c570dbff-1b65-4792-a2b0-342b24ba921d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Gathering all the stopwords\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "stopwords = list(STOP_WORDS)\n",
        "print(len(stopwords))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmsVXflwcrrJ",
        "colab_type": "code",
        "outputId": "33ad0c05-4ae0-4c49-9be1-a6ab1adaa812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Loading yelp dataset\n",
        "data_yelp = pd.read_csv(\"/content/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset/datasets/yelp_labelled.txt\",\n",
        "                        sep='\\t', header= None)\n",
        "data_yelp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0                           Wow... Loved this place.  1\n",
              "1                                 Crust is not good.  0\n",
              "2          Not tasty and the texture was just nasty.  0\n",
              "3  Stopped by during the late May bank holiday of...  1\n",
              "4  The selection on the menu was great and so wer...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY9NeiFAdD0v",
        "colab_type": "code",
        "outputId": "cc1a9800-fc37-4fa3-d5ae-149244b8d427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Adding column names to the dataframe\n",
        "columnName = ['Review','Sentiment']\n",
        "data_yelp.columns = columnName\n",
        "data_yelp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0                           Wow... Loved this place.          1\n",
              "1                                 Crust is not good.          0\n",
              "2          Not tasty and the texture was just nasty.          0\n",
              "3  Stopped by during the late May bank holiday of...          1\n",
              "4  The selection on the menu was great and so wer...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUdmn-6AeckX",
        "colab_type": "code",
        "outputId": "a93d9cc1-29ac-4e33-8b68-189e649a320c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data_yelp.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQueov_XdL7b",
        "colab_type": "code",
        "outputId": "ddcabed8-a2c6-4dbd-dc39-b55808a1c95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Adding Amazon dataset and adding its column name\n",
        "data_amz = pd.read_csv(\"/content/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset/datasets/amazon_cells_labelled.txt\",\n",
        "                        sep='\\t', header= None)\n",
        "data_amz.columns = columnName\n",
        "data_amz.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0  So there is no way for me to plug it in here i...          0\n",
              "1                        Good case, Excellent value.          1\n",
              "2                             Great for the jawbone.          1\n",
              "3  Tied to charger for conversations lasting more...          0\n",
              "4                                  The mic is great.          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nz_dIL6efAL",
        "colab_type": "code",
        "outputId": "ebdd55fb-19f3-4fd7-c83e-ae4a111b55df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data_amz.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlmibXduefiM",
        "colab_type": "code",
        "outputId": "54942c4b-b3b9-49d2-8ed4-96d9e36ef9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Adding IMdB dataset and adding its column name\n",
        "data_imdb = pd.read_csv(\"/content/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset/datasets/imdb_labelled.txt\",\n",
        "                        sep='\\t', header= None)\n",
        "data_imdb.columns = columnName\n",
        "data_imdb.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0  A very, very, very slow-moving, aimless movie ...          0\n",
              "1  Not sure who was more lost - the flat characte...          0\n",
              "2  Attempting artiness with black & white and cle...          0\n",
              "3       Very little music or anything to speak of.            0\n",
              "4  The best scene in the movie was when Gerardo i...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-KvuCuHeuUg",
        "colab_type": "code",
        "outputId": "c65c1fd1-f36f-4064-be72-ee7cfeb16190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data_imdb.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(748, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_XOzJ3Key4E",
        "colab_type": "code",
        "outputId": "665e1e7c-eb23-4d3d-8c60-15950fc02ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Merging all the three dataframes\n",
        "data = data_yelp.append([data_amz, data_imdb], ignore_index=True)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2748, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHl1q35JfCmQ",
        "colab_type": "code",
        "outputId": "089cebc8-75d6-45b8-9258-b2942e53a4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Sentiment ditribution in the dataset\n",
        "data.Sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1386\n",
              "0    1362\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9L8Vq3jfHrl",
        "colab_type": "code",
        "outputId": "92f815a0-77b6-4836-f9cc-239892cc7641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Getting information regarding the null entries in the dataset\n",
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review       0\n",
              "Sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH5Ca5fvfN1J",
        "colab_type": "code",
        "outputId": "c48f7813-0ad5-4c8d-854d-1ada68472eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "punct = string.punctuation\n",
        "print(punct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqrObkD7h0mQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Here in the reviews we will find many stop words which do not add any meaning to the review.\n",
        "Also punctuations will be encountered in the review which which will be considered as a seperate token by our model\n",
        "So removing all the stop words and punctuation so that our model can train efficiently\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKxbf5WBfhwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataCleaning(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    if token.lemma_ != '-PRON-':\n",
        "      temp = token.lemma_.lower().strip()\n",
        "    else:\n",
        "      temp = token.lower_\n",
        "    tokens.append(temp)\n",
        "  clean_tokens = []\n",
        "  for token in tokens:\n",
        "    if token not in punct and token not in stopwords:\n",
        "      clean_tokens.append(token)\n",
        "  return clean_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVT_Yym0js_N",
        "colab_type": "code",
        "outputId": "4dd878b2-34be-400d-abb1-d52fd3c6c32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "dataCleaning(\"Today we are having heavy rainfall, We recommend you to stay at your home and be safe, Do not start running here and there\")\n",
        "# All the useful words are returned, no punctuations no stop words and in the lemmatized form"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today',\n",
              " 'heavy',\n",
              " 'rainfall',\n",
              " 'recommend',\n",
              " 'stay',\n",
              " 'home',\n",
              " 'safe',\n",
              " 'start',\n",
              " 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTxGmm0_ktFt",
        "colab_type": "code",
        "outputId": "8be908e7-2dd9-46a4-d8a2-ade433486049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Spillting the train and test data\n",
        "X = data['Review']\n",
        "y = data['Sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(X_train.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2198,) (550,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKwAQK5qktD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the model and pipeline\n",
        "tfidf = TfidfVectorizer(tokenizer = dataCleaning)\n",
        "svm = LinearSVC()\n",
        "steps = [('tfidf',tfidf),('svm',svm)]\n",
        "pipe = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlaTICpJktC1",
        "colab_type": "code",
        "outputId": "f0bfe29b-b61d-4395-f41c-77d6d4ee356b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Training the model\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function dataCleaning at 0x7f1831926048>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('svm',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavuQuDJktAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing on the test dataset\n",
        "y_pred = pipe.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mPpPGkDmCzX",
        "colab_type": "code",
        "outputId": "32d56cfe-f7f4-4e0d-ae07-c6ab0c12bfde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Printing the classification report and the confusion matrix\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"\\n\\n\")\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.77      0.80       278\n",
            "           1       0.78      0.83      0.80       272\n",
            "\n",
            "    accuracy                           0.80       550\n",
            "   macro avg       0.80      0.80      0.80       550\n",
            "weighted avg       0.80      0.80      0.80       550\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[214  64]\n",
            " [ 46 226]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOcACsrQks9x",
        "colab_type": "code",
        "outputId": "373e6231-6ae6-4473-ddbf-a4b88cb8386a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testing on random inputs\n",
        "pipe.predict([\"Wow you are an amazing person\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfo44Ij9m2OY",
        "colab_type": "code",
        "outputId": "cd64a1e6-6882-4fc9-9f81-c6cf3e861b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pipe.predict([\"you suck\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbOH_5vcgO6s",
        "colab_type": "text"
      },
      "source": [
        "### Footnotes\n",
        "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
        "\n",
        "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976\n"
      ]
    }
  ]
}